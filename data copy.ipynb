{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_fake = pd.read_csv(\"Fake.csv\")\n",
    "df_true = pd.read_csv(\"True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add class labels\n",
    "df_fake[\"class\"] = 0\n",
    "df_true[\"class\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake_manual_testing = df_fake.sample(n=5000, random_state=42)\n",
    "\n",
    "# Remove the selected rows from df_fake\n",
    "df_fake = df_fake.drop(df_fake_manual_testing.index)\n",
    "\n",
    "# Randomly select 10,000 rows from df_true for manual testing\n",
    "df_true_manual_testing = df_true.sample(n=5000, random_state=42)\n",
    "\n",
    "# Remove the selected rows from df_true\n",
    "df_true = df_true.drop(df_true_manual_testing.index)\n",
    "\n",
    "df_fake_manual_testing[\"class\"] = 0\n",
    "df_true_manual_testing[\"class\"] = 1\n",
    "\n",
    "df_manual_testing = pd.concat([df_fake_manual_testing, df_true_manual_testing], axis=0)\n",
    "df_manual_testing.to_csv(\"manual_testing.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging datasets\n",
    "df_merge = pd.concat([df_fake_manual_testing, df_true_manual_testing], axis=0)\n",
    "\n",
    "# Data preprocessing\n",
    "df_merge = df_merge.drop([\"title\", \"subject\", \"date\"], axis=1)\n",
    "df_merge = df_merge.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Text preprocessing function\n",
    "def wordopt(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\",\" \",text) \n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text preprocessing\n",
    "df_merge[\"text\"] = df_merge[\"text\"].apply(wordopt)\n",
    "\n",
    "# Splitting the data\n",
    "x = df_merge[\"text\"]\n",
    "y = df_merge[\"class\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "vectorization = TfidfVectorizer()\n",
    "xv_train = vectorization.fit_transform(x_train)\n",
    "xv_test = vectorization.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "lr_model = LogisticRegression()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "gb_model = GradientBoostingClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Train the models\n",
    "lr_model.fit(xv_train, y_train)\n",
    "dt_model.fit(xv_train, y_train)\n",
    "gb_model.fit(xv_train, y_train)\n",
    "rf_model.fit(xv_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "lr_pred = lr_model.predict(xv_test)\n",
    "dt_pred = dt_model.predict(xv_test)\n",
    "gb_pred = gb_model.predict(xv_test)\n",
    "rf_pred = rf_model.predict(xv_test)\n",
    "\n",
    "# Model Evaluation\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.972\n",
      "Decision Tree Accuracy: 0.9948\n",
      "Gradient Boosting Accuracy: 0.9952\n",
      "Random Forest Accuracy: 0.9808\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1271\n",
      "           1       0.97      0.98      0.97      1229\n",
      "\n",
      "    accuracy                           0.97      2500\n",
      "   macro avg       0.97      0.97      0.97      2500\n",
      "weighted avg       0.97      0.97      0.97      2500\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1271\n",
      "           1       0.99      1.00      0.99      1229\n",
      "\n",
      "    accuracy                           0.99      2500\n",
      "   macro avg       0.99      0.99      0.99      2500\n",
      "weighted avg       0.99      0.99      0.99      2500\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      1271\n",
      "           1       0.99      1.00      1.00      1229\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      1.00      1.00      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1271\n",
      "           1       0.98      0.98      0.98      1229\n",
      "\n",
      "    accuracy                           0.98      2500\n",
      "   macro avg       0.98      0.98      0.98      2500\n",
      "weighted avg       0.98      0.98      0.98      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "print(\"Gradient Boosting Accuracy:\", gb_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, lr_pred))\n",
    "print(\"Decision Tree Classification Report:\\n\", classification_report(y_test, dt_pred))\n",
    "print(\"Gradient Boosting Classification Report:\\n\", classification_report(y_test, gb_pred))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
